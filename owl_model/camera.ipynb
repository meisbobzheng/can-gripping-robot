{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "cap = cv.VideoCapture(1)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    cv.imshow('frame', frame)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image_0.jpg\n",
      "Saved image_1.jpg\n",
      "Saved image_2.jpg\n",
      "Saved image_3.jpg\n",
      "Saved image_4.jpg\n",
      "Saved image_5.jpg\n",
      "Saved image_6.jpg\n",
      "Saved image_7.jpg\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(1) \n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    cv2.imshow('Calibration Frame', frame)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('s'):  # Save image when 's' is pressed\n",
    "        cv2.imwrite(f'C:/Users/panta/Desktop/owl_model/callibration_images/image_{count}.jpg', frame)\n",
    "        print(f\"Saved image_{count}.jpg\")\n",
    "        count += 1\n",
    "    elif key == ord('q'): \n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\calibration.cpp:1379: error: (-215:Assertion failed) nimages > 0 in function 'cv::calibrateCameraRO'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(imgpoints)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Perform camera calibration\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m ret, mtx, dist, rvecs, tvecs \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalibrateCamera\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCamera matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, mtx)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\calibration.cpp:1379: error: (-215:Assertion failed) nimages > 0 in function 'cv::calibrateCameraRO'\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Define the checkerboard dimensions\n",
    "CHECKERBOARD = (11, 8)\n",
    "\n",
    "objpoints = []  # 3D points in real-world space\n",
    "imgpoints = []  # 2D points in image plane\n",
    "\n",
    "# Prepare the object points (same for all images)\n",
    "objp = np.zeros((CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)\n",
    "\n",
    "# Load all calibration images\n",
    "images = glob.glob('.\\\\callibration_images/*.jpg')\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect corners\n",
    "    ret, corners = cv2.findChessboardCorners(img, CHECKERBOARD, None)\n",
    "    if ret:\n",
    "        imgpoints.append(corners)\n",
    "        objpoints.append(objp)\n",
    "\n",
    "\n",
    "# Perform camera calibration\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "# Print results\n",
    "print(\"Camera matrix:\\n\", mtx)\n",
    "print(\"Distortion coefficients:\\n\", dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False None\n"
     ]
    }
   ],
   "source": [
    "# Define the checkerboard dimensions (number of inner corners)\n",
    "CHECKERBOARD = (11, 8)\n",
    "\n",
    "img = cv2.imread('.//callibration_images/image_0.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find the chessboard corners\n",
    "ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, cv2.CALIB_CB_ADAPTIVE_THRESH)\n",
    "\n",
    "print(ret, corners)\n",
    "if ret:\n",
    "    cv2.drawChessboardCorners(img, CHECKERBOARD, corners, ret)\n",
    "    cv2.imshow('Corners Detected', img)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to the ArUco Marker Detector!\n",
      "  \n",
      "This program:\n",
      "  - Detects ArUco markers using OpenCV and Python\n",
      "\n",
      "[INFO] detecting 'DICT_4X4_50' markers...\n"
     ]
    }
   ],
   "source": [
    "  from __future__ import print_function # Python 2/3 compatibility\n",
    "import cv2 # Import the OpenCV library\n",
    "import numpy as np # Import Numpy library\n",
    "import sys\n",
    " \n",
    "# Project: ArUco Marker Detector\n",
    "# Date created: 12/18/2021\n",
    "# Python version: 3.8\n",
    "# Reference: https://www.pyimagesearch.com/2020/12/21/detecting-aruco-markers-with-opencv-and-python/\n",
    " \n",
    "desired_aruco_dictionary = \"DICT_4X4_50\"\n",
    " \n",
    "# The different ArUco dictionaries built into the OpenCV library. \n",
    "ARUCO_DICT = {\n",
    "  \"DICT_4X4_50\": cv2.aruco.DICT_4X4_50,\n",
    "  \"DICT_4X4_100\": cv2.aruco.DICT_4X4_100,\n",
    "  \"DICT_4X4_250\": cv2.aruco.DICT_4X4_250,\n",
    "  \"DICT_4X4_1000\": cv2.aruco.DICT_4X4_1000,\n",
    "  \"DICT_5X5_50\": cv2.aruco.DICT_5X5_50,\n",
    "  \"DICT_5X5_100\": cv2.aruco.DICT_5X5_100,\n",
    "  \"DICT_5X5_250\": cv2.aruco.DICT_5X5_250,\n",
    "  \"DICT_5X5_1000\": cv2.aruco.DICT_5X5_1000,\n",
    "  \"DICT_6X6_50\": cv2.aruco.DICT_6X6_50,\n",
    "  \"DICT_6X6_100\": cv2.aruco.DICT_6X6_100,\n",
    "  \"DICT_6X6_250\": cv2.aruco.DICT_6X6_250,\n",
    "  \"DICT_6X6_1000\": cv2.aruco.DICT_6X6_1000,\n",
    "  \"DICT_7X7_50\": cv2.aruco.DICT_7X7_50,\n",
    "  \"DICT_7X7_100\": cv2.aruco.DICT_7X7_100,\n",
    "  \"DICT_7X7_250\": cv2.aruco.DICT_7X7_250,\n",
    "  \"DICT_7X7_1000\": cv2.aruco.DICT_7X7_1000,\n",
    "  \"DICT_ARUCO_ORIGINAL\": cv2.aruco.DICT_ARUCO_ORIGINAL\n",
    "}\n",
    "  \n",
    "def main():\n",
    "  \"\"\"\n",
    "  Main method of the program.\n",
    "  \"\"\"\n",
    "\n",
    "  # Load the ArUco dictionary\n",
    "  print(\"[INFO] detecting '{}' markers...\".format(\n",
    "    desired_aruco_dictionary))\n",
    "  this_aruco_dictionary = cv2.aruco.getPredefinedDictionary(ARUCO_DICT[desired_aruco_dictionary])\n",
    "  this_aruco_parameters = cv2.aruco.DetectorParameters()\n",
    "  detector = cv2.aruco.ArucoDetector(this_aruco_dictionary, this_aruco_parameters)\n",
    "\n",
    "  # Start the video stream\n",
    "  cap = cv2.VideoCapture(1)\n",
    "   \n",
    "  while(True):\n",
    "  \n",
    "    # Capture frame-by-frame\n",
    "    # This method returns True/False as well\n",
    "    # as the video frame.\n",
    "    ret, frame = cap.read()  \n",
    "     \n",
    "    # Detect ArUco markers in the video frame\n",
    "    (corners, ids, rejected) = detector.detectMarkers(frame)\n",
    "       \n",
    "    # Check that at least one ArUco marker was detected\n",
    "    if len(corners) > 0:\n",
    "      # Flatten the ArUco IDs list\n",
    "      ids = ids.flatten()\n",
    "       \n",
    "      # Loop over the detected ArUco corners\n",
    "      for (marker_corner, marker_id) in zip(corners, ids):\n",
    "       \n",
    "        # Extract the marker corners\n",
    "        corners = marker_corner.reshape((4, 2))\n",
    "        (top_left, top_right, bottom_right, bottom_left) = corners\n",
    "         \n",
    "        # Convert the (x,y) coordinate pairs to integers\n",
    "        top_right = (int(top_right[0]), int(top_right[1]))\n",
    "        bottom_right = (int(bottom_right[0]), int(bottom_right[1]))\n",
    "        bottom_left = (int(bottom_left[0]), int(bottom_left[1]))\n",
    "        top_left = (int(top_left[0]), int(top_left[1]))\n",
    "         \n",
    "        # Draw the bounding box of the ArUco detection\n",
    "        cv2.line(frame, top_left, top_right, (0, 255, 0), 2)\n",
    "        cv2.line(frame, top_right, bottom_right, (0, 255, 0), 2)\n",
    "        cv2.line(frame, bottom_right, bottom_left, (0, 255, 0), 2)\n",
    "        cv2.line(frame, bottom_left, top_left, (0, 255, 0), 2)\n",
    "         \n",
    "        # Calculate and draw the center of the ArUco marker\n",
    "        center_x = int((top_left[0] + bottom_right[0]) / 2.0)\n",
    "        center_y = int((top_left[1] + bottom_right[1]) / 2.0)\n",
    "        cv2.circle(frame, (center_x, center_y), 4, (0, 0, 255), -1)\n",
    "         \n",
    "        # Draw the ArUco marker ID on the video frame\n",
    "        # The ID is always located at the top_left of the ArUco marker\n",
    "        cv2.putText(frame, str(marker_id), \n",
    "          (top_left[0], top_left[1] - 15),\n",
    "          cv2.FONT_HERSHEY_SIMPLEX,\n",
    "          0.5, (0, 255, 0), 2)\n",
    "  \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',frame)\n",
    "          \n",
    "    # If \"q\" is pressed on the keyboard, \n",
    "    # exit this loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "      break\n",
    "  \n",
    "  # Close down the video stream\n",
    "  cap.release()\n",
    "  cv2.destroyAllWindows()\n",
    "   \n",
    "if __name__ == '__main__':\n",
    "  print(__doc__)\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
